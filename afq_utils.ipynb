{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"  \n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Set\n",
    "\n",
    "\n",
    "model_id = \"./models/gpt-oss-120b\".strip()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def texts_to_last_hidden_embeddings(\n",
    "    texts,\n",
    "    batch_size=8,\n",
    "    max_length=None,\n",
    "    pooling=\"last_token\",\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "    emb_list = []\n",
    "\n",
    "    for start in tqdm(\n",
    "        range(0, len(texts), batch_size),\n",
    "        desc=\"Encoding batches\",\n",
    "        total=(len(texts) + batch_size - 1) // batch_size,\n",
    "    ):\n",
    "        batch_texts = texts[start : start + batch_size]\n",
    "\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "        out = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "        last_layer = out.hidden_states[-1]\n",
    "\n",
    "        if pooling == \"last_token\":\n",
    "            last_idx = enc[\"attention_mask\"].sum(dim=1) - 1\n",
    "            last_idx = last_idx.clamp(min=0)\n",
    "\n",
    "            pooled = last_layer[\n",
    "                torch.arange(last_layer.size(0), device=device), last_idx\n",
    "            ]\n",
    "\n",
    "        elif pooling == \"mean\":\n",
    "            mask = enc[\"attention_mask\"].unsqueeze(-1).to(last_layer.dtype)\n",
    "            pooled = (last_layer * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown pooling={pooling}\")\n",
    "\n",
    "        emb_list.append(pooled.float().cpu().numpy())\n",
    "\n",
    "    return np.concatenate(emb_list, axis=0)\n",
    "\n",
    "\n",
    "with open(\"./putnam.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_fuse_pairs(\n",
    "    emb_path: str,\n",
    "    minority_size: int,\n",
    "    K: int = 5,\n",
    "    max_iterations: int = 50,\n",
    ") -> Tuple[List[Tuple[int, int]],\n",
    "           List[Tuple[int, int]],\n",
    "           List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        emb_path: path to .npy file of shape (N, D)\n",
    "        minority_size: number of B (non-solvable) samples at the bottom\n",
    "        K: per-question fuse pair cap\n",
    "        max_iterations: how many similarity ranks to traverse\n",
    "\n",
    "    Returns:\n",
    "        AA_pairs: list of (i, j) both in A\n",
    "        AB_pairs: list of (i, j) one in A, one in B\n",
    "        final_pairs: union of AA and AB (unique pairs)\n",
    "    \"\"\"\n",
    "\n",
    "    emb = np.load(emb_path)  # (N, D)\n",
    "    N = emb.shape[0]\n",
    "\n",
    "    # Split A / B\n",
    "    A_end = N - minority_size\n",
    "    is_A = np.zeros(N, dtype=bool)\n",
    "    is_A[:A_end] = True\n",
    "\n",
    "    # Normalize embeddings for cosine similarity\n",
    "    emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "    # Full cosine similarity matrix\n",
    "    sim = emb @ emb.T\n",
    "    np.fill_diagonal(sim, -np.inf)\n",
    "\n",
    "    # Pre-sort neighbors for each question\n",
    "    sorted_neighbors = np.argsort(-sim, axis=1)\n",
    "\n",
    "    usage = np.zeros(N, dtype=int)\n",
    "    used_pairs: Set[Tuple[int, int]] = set()\n",
    "\n",
    "    AA_pairs = []\n",
    "    AB_pairs = []\n",
    "\n",
    "    for it in range(max_iterations):\n",
    "        for i in range(N):\n",
    "            if usage[i] >= K:\n",
    "                continue\n",
    "\n",
    "            # Guard: not enough neighbors\n",
    "            if it >= sorted_neighbors.shape[1]:\n",
    "                continue\n",
    "\n",
    "            j = sorted_neighbors[i, it]\n",
    "\n",
    "            if usage[j] >= K:\n",
    "                continue\n",
    "\n",
    "            a, b = min(i, j), max(i, j)\n",
    "            if (a, b) in used_pairs:\n",
    "                continue\n",
    "\n",
    "            # Accept pair\n",
    "            used_pairs.add((a, b))\n",
    "            usage[i] += 1\n",
    "            usage[j] += 1\n",
    "\n",
    "            if is_A[i] and is_A[j]:\n",
    "                AA_pairs.append((a, b))\n",
    "            elif is_A[i] ^ is_A[j]:\n",
    "                AB_pairs.append((a, b))\n",
    "            # B+B pairs are ignored by construction\n",
    "\n",
    "    # Final non-overlapping pair list\n",
    "    final_pairs = list(set(AA_pairs).union(set(AB_pairs)))\n",
    "\n",
    "    return AA_pairs, AB_pairs, final_pairs\n",
    "\n",
    "\n",
    "aa , ab , final = generate_fuse_pairs(\n",
    "    emb_path=\"./questions.npy\",\n",
    "    minority_size=0,\n",
    "    K=5,\n",
    "    max_iterations=5,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4499a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = []\n",
    "# c = 0\n",
    "# for x in ds:\n",
    "#     try:\n",
    "#         if int(x[\"expected_answer\"]):\n",
    "#             if x[\"problem_source\"] == \"aops_c7_college_math\":\n",
    "#                 rate  = (x[\"pass_rate_72b_tir\"])\n",
    "        \n",
    "#                 if 0.0 < float(rate) < 0.3:\n",
    "\n",
    "#                     samples.append(\n",
    "#                         {\n",
    "#                             \"rate\" :  float(rate), \n",
    "#                             \"question\" : x[\"problem\"] , \n",
    "#                             \"solution\" : x[\"generated_solution\"] , \n",
    "#                             \"value\" : int(x[\"expected_answer\"])\n",
    "#                         }\n",
    "#                     )\n",
    "#                     c+=1\n",
    "#                     if c==300:\n",
    "#                         break\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#     except Exception as e :\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58904fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"nvidia/OpenMathReasoning\" , streaming = True , split = \"tir\")\n",
    "\n",
    "\n",
    "data = []\n",
    "c = 0\n",
    "for x in ds:\n",
    "    try:\n",
    "        if int(x[\"expected_answer\"]):\n",
    "            if x[\"problem_source\"] == \"aops_c7_college_math\":\n",
    "                rate  = (x[\"pass_rate_72b_tir\"])\n",
    "        \n",
    "                if 0.0 < float(rate) < 0.3:\n",
    "\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"rate\" :  float(rate), \n",
    "                            \"question\" : x[\"problem\"] , \n",
    "                            \"solution\" : x[\"generated_solution\"] , \n",
    "                            \"value\" : int(x[\"expected_answer\"])\n",
    "                        }\n",
    "                    )\n",
    "                    c+=1\n",
    "                    if c==300:\n",
    "                        break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    except Exception as e :\n",
    "        pass\n",
    "\n",
    "unique = []\n",
    "seen = set()\n",
    "\n",
    "for x in data:\n",
    "    q = x[\"question\"].strip()\n",
    "    if q not in seen:\n",
    "        seen.add(q)\n",
    "        unique.append(x)\n",
    "\n",
    "data = unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da506b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "samples = []\n",
    "questions = []\n",
    "d = \"/data/aneesh/datasets/nvidia_cot/data\"\n",
    "files = os.listdir(d)\n",
    "for x in tqdm(files):\n",
    "    if x.endswith(\".parquet\"):\n",
    "\n",
    "        df = pd.read_parquet(os.path.join(d , x))\n",
    "        for i in range(len(df)):\n",
    "\n",
    "            ans = df.iloc[i][\"expected_answer\"]\n",
    "            try:\n",
    "                if len(samples) == 20_000:\n",
    "                    break\n",
    "                \n",
    "                if df.iloc[i][\"problem_source\"] not in [\"aops_c7_college_math\" , \"aops_c6_high_school_olympiads\"  , \"c7_college_math\" , \"aops_c4_high_school_math\"]:\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     if int(df.iloc[i][\"pass_rate_72b_tir\"]) >  0.4 :\n",
    "                #         continue\n",
    "                # except:\n",
    "                #     pass\n",
    "\n",
    "                if df.iloc[i][\"problem\"] in questions:\n",
    "                    continue\n",
    "\n",
    "                if 0 <= int(ans) < 100_000:\n",
    "                    samples.append(\n",
    "                        {\n",
    "                            \"question\" : df.iloc[i][\"problem\"] , \n",
    "                            \"answer\" :  int(ans)  , \n",
    "                            \"pass_rate_72b_tir\" : df.iloc[i][\"pass_rate_72b_tir\"] , \n",
    "                            \"solution\" : df.iloc[i][\"generated_solution\"].replace(\"<think>\" , \"\").replace(\"</think>\" , \"\")\n",
    "                        }\n",
    "                    )\n",
    "                    questions.append(df.iloc[i][\"problem\"])\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd81671",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aa) , len(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868578c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for x in aa:\n",
    "    first = int(x[0])\n",
    "    second = int(x[1])\n",
    "    samples.append(\n",
    "        {\n",
    "            \"question_1\" : data[first][\"question\"], \n",
    "            \"question_2\" : data[second][\"question\"],\n",
    "            \n",
    "            \"answer_1\" : data[first][\"answer\"],\n",
    "            \"answer_2\" : data[second][\"answer\"],\n",
    "\n",
    "            \"split\" : \"neutral\"\n",
    "\n",
    "        }\n",
    "    )\n",
    "    \n",
    "\n",
    "# for x in ab:\n",
    "#     first = int(x[0])\n",
    "#     second = int(x[1])\n",
    "#     samples.append(\n",
    "#         {\n",
    "#             \"question_1\" : data[first][\"question\"], \n",
    "#             \"question_2\" : data[second][\"question\"],\n",
    "            \n",
    "#             \"answer_1\" : data[first][\"answer\"],\n",
    "#             \"answer_2\" : data[second][\"answer\"],\n",
    "\n",
    "#             \"split\" : \"correct_and_incorrect\"\n",
    "#         }\n",
    "#     )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_aimo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
